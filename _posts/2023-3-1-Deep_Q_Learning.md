# Deep Q Learning

注意，一般来说，游戏分数可能取决于整个先前的动作和观察顺序；关于动作的反馈可能仅在经过数千个时间步骤之后才被接收。

我们可以将标准的强化学习方法应用于MDP，只需使用完整序列st作为时间t的状态表示。

我们做了一个标准假设，即未来的奖励按每个时间步长的因子进行折现，
